{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d93374",
   "metadata": {
    "_cell_guid": "fd2419b3-7c82-45b1-a4b4-b8998739bc79",
    "_uuid": "9c380d46-285e-4d80-af22-c8521a872f39",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:15:18.613813Z",
     "iopub.status.busy": "2024-12-11T18:15:18.613131Z",
     "iopub.status.idle": "2024-12-11T18:15:52.323432Z",
     "shell.execute_reply": "2024-12-11T18:15:52.322107Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 33.717961,
     "end_time": "2024-12-11T18:15:52.325515",
     "exception": false,
     "start_time": "2024-12-11T18:15:18.607554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers datasets peft bitsandbytes trl\n",
    "!pip install -q accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197ca146",
   "metadata": {
    "_cell_guid": "fe4ac529-28b3-4a64-8062-361cf6f1e555",
    "_uuid": "8580db54-1e87-4223-a109-8248ad090dbc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:15:52.336423Z",
     "iopub.status.busy": "2024-12-11T18:15:52.336094Z",
     "iopub.status.idle": "2024-12-11T18:15:56.078956Z",
     "shell.execute_reply": "2024-12-11T18:15:56.077941Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.750554,
     "end_time": "2024-12-11T18:15:56.080983",
     "exception": false,
     "start_time": "2024-12-11T18:15:52.330429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3c52d5",
   "metadata": {
    "_cell_guid": "fcb57107-962c-43df-adda-10984e64b046",
    "_uuid": "b7b7d447-a0a5-494c-b2e7-711d162d5989",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:15:56.092530Z",
     "iopub.status.busy": "2024-12-11T18:15:56.092072Z",
     "iopub.status.idle": "2024-12-11T18:16:12.955686Z",
     "shell.execute_reply": "2024-12-11T18:16:12.955018Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 16.870801,
     "end_time": "2024-12-11T18:16:12.957748",
     "exception": false,
     "start_time": "2024-12-11T18:15:56.086947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    AutoConfig\n",
    ")\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from huggingface_hub import login\n",
    "from peft import LoraConfig, get_peft_model,PeftModel\n",
    "from trl import SFTTrainer\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # For progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651951eb",
   "metadata": {
    "_cell_guid": "20eb4410-dc5e-472c-9d5d-234efa3cff64",
    "_uuid": "d9cecba2-cdd4-4195-9327-03113479f4d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:12.968315Z",
     "iopub.status.busy": "2024-12-11T18:16:12.967747Z",
     "iopub.status.idle": "2024-12-11T18:16:12.978100Z",
     "shell.execute_reply": "2024-12-11T18:16:12.977311Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01743,
     "end_time": "2024-12-11T18:16:12.979791",
     "exception": false,
     "start_time": "2024-12-11T18:16:12.962361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85935ec9",
   "metadata": {
    "_cell_guid": "397dcfdf-a55b-4322-bf66-337e7bd228fe",
    "_uuid": "d9bf8682-eac9-4b42-85e3-9638418d0686",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:12.989690Z",
     "iopub.status.busy": "2024-12-11T18:16:12.989213Z",
     "iopub.status.idle": "2024-12-11T18:16:12.994007Z",
     "shell.execute_reply": "2024-12-11T18:16:12.993179Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011396,
     "end_time": "2024-12-11T18:16:12.995584",
     "exception": false,
     "start_time": "2024-12-11T18:16:12.984188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available:2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of GPUs Available:{torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe5ce1",
   "metadata": {
    "_cell_guid": "3a1fe8bd-0eab-4d31-98a9-2c4d80c8c34d",
    "_uuid": "2a745720-2b36-4fa3-89da-28abc9436bca",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:13.005197Z",
     "iopub.status.busy": "2024-12-11T18:16:13.004953Z",
     "iopub.status.idle": "2024-12-11T18:16:13.106027Z",
     "shell.execute_reply": "2024-12-11T18:16:13.104996Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.108063,
     "end_time": "2024-12-11T18:16:13.107923",
     "exception": false,
     "start_time": "2024-12-11T18:16:12.999860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# token = \"your_hugging_face_token\"\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9efe88",
   "metadata": {
    "_cell_guid": "0a2e44e6-fde9-4d7a-958f-2a3e4140383d",
    "_uuid": "267efb0c-2d04-4681-8997-80cccd7b33c2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:13.118515Z",
     "iopub.status.busy": "2024-12-11T18:16:13.118222Z",
     "iopub.status.idle": "2024-12-11T18:16:13.122250Z",
     "shell.execute_reply": "2024-12-11T18:16:13.121392Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011313,
     "end_time": "2024-12-11T18:16:13.124026",
     "exception": false,
     "start_time": "2024-12-11T18:16:13.112713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = \"\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c81789a",
   "metadata": {
    "_cell_guid": "4fcdf50d-af31-44e1-a708-b8525dae1af3",
    "_uuid": "50f2afd2-395c-45be-a043-60580c6fdef9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:13.134260Z",
     "iopub.status.busy": "2024-12-11T18:16:13.133993Z",
     "iopub.status.idle": "2024-12-11T18:16:13.140552Z",
     "shell.execute_reply": "2024-12-11T18:16:13.139698Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014062,
     "end_time": "2024-12-11T18:16:13.142685",
     "exception": false,
     "start_time": "2024-12-11T18:16:13.128623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = {\"lora_config1\" : LoraConfig(\n",
    "    r=256,\n",
    "    lora_alpha=512,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "),\n",
    " \"lora_config2\" : LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "),\n",
    " \"lora_config3\" : LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "),\n",
    " \"lora_config4\" : LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "),\n",
    " \"lora_config5\" : LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2a5bea",
   "metadata": {
    "_cell_guid": "863e45ef-ca14-4845-96a5-1eeb9723c700",
    "_uuid": "82e94537-f76c-4423-90e2-c65fa6550129",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:13.153308Z",
     "iopub.status.busy": "2024-12-11T18:16:13.153043Z",
     "iopub.status.idle": "2024-12-11T18:16:13.157830Z",
     "shell.execute_reply": "2024-12-11T18:16:13.157221Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011806,
     "end_time": "2024-12-11T18:16:13.159386",
     "exception": false,
     "start_time": "2024-12-11T18:16:13.147580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16b0b45",
   "metadata": {
    "_cell_guid": "9b19b402-b808-4b80-8777-48dd9aea6102",
    "_uuid": "237366b8-eccd-4cba-850b-9f92585b1601",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:13.169326Z",
     "iopub.status.busy": "2024-12-11T18:16:13.169082Z",
     "iopub.status.idle": "2024-12-11T18:16:14.622112Z",
     "shell.execute_reply": "2024-12-11T18:16:14.621089Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.460183,
     "end_time": "2024-12-11T18:16:14.624231",
     "exception": false,
     "start_time": "2024-12-11T18:16:13.164048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99ccbb227f7441fa2c22345d08f2db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9af06a27914995a14852fd192c9691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6197238361cc4470836f5e2e34ddf8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f3176b",
   "metadata": {
    "_cell_guid": "c7df9bd4-554c-4948-a43d-27a92dc849ab",
    "_uuid": "7e23becc-a142-4330-8a70-4b25fed24bb0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:14.635795Z",
     "iopub.status.busy": "2024-12-11T18:16:14.635209Z",
     "iopub.status.idle": "2024-12-11T18:16:14.640267Z",
     "shell.execute_reply": "2024-12-11T18:16:14.639426Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01262,
     "end_time": "2024-12-11T18:16:14.641990",
     "exception": false,
     "start_time": "2024-12-11T18:16:14.629370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define default tokens\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "\n",
    "special_tokens_dict = {}\n",
    "if tokenizer.pad_token is None:\n",
    "    special_tokens_dict['pad_token'] = DEFAULT_PAD_TOKEN\n",
    "if tokenizer.eos_token is None:\n",
    "    special_tokens_dict['eos_token'] = DEFAULT_EOS_TOKEN\n",
    "if tokenizer.bos_token is None:\n",
    "    special_tokens_dict['bos_token'] = DEFAULT_BOS_TOKEN\n",
    "\n",
    "if special_tokens_dict:\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa09c343",
   "metadata": {
    "_cell_guid": "aa7715fb-f01b-4b23-8ab1-e86d55a608e0",
    "_uuid": "90168d3f-dcb5-4295-bf79-e1bd7f1a3298",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:16:14.652523Z",
     "iopub.status.busy": "2024-12-11T18:16:14.652038Z",
     "iopub.status.idle": "2024-12-11T18:17:17.710095Z",
     "shell.execute_reply": "2024-12-11T18:17:17.709471Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 63.065424,
     "end_time": "2024-12-11T18:17:17.712080",
     "exception": false,
     "start_time": "2024-12-11T18:16:14.646656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e6091a46d64c6e9d840ef7ae345873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3776a583486a4f32bdc60d2b246d89a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14020660c0394262bd3998eb8bfe9873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    token=token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d4139a",
   "metadata": {
    "_cell_guid": "35581e32-6ac2-48c6-992f-f7cd5c4e4afc",
    "_uuid": "a6f4a44c-2dfc-4bb1-a766-16319776f89f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:17:17.724970Z",
     "iopub.status.busy": "2024-12-11T18:17:17.724589Z",
     "iopub.status.idle": "2024-12-11T18:17:17.731326Z",
     "shell.execute_reply": "2024-12-11T18:17:17.730456Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015041,
     "end_time": "2024-12-11T18:17:17.732996",
     "exception": false,
     "start_time": "2024-12-11T18:17:17.717955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Format inputs with the instruction\n",
    "    inputs = [\n",
    "        f\"<|begin_of_text|><|start_header_id|>system <|end_header_id|>\"\n",
    "        \"You are an expert math assistant<|eot_id|><|start_header_id|>user <|end_header_id|>\"\n",
    "        f\"Solve the following math problem: {problem}\\n\"\n",
    "        \"Show all intermediate steps and please mandatorily include the final answer in LaTeX format in a box like \\\\boxed{{}}.\"\n",
    "        \"<|eot_id|><|start_header_id|> assistant <|end_header_id|>\"for problem in examples['problem']\n",
    "    ]\n",
    "    # Append the solution with EOS token\n",
    "    targets = [\n",
    "        f\"{solution}{tokenizer.eos_token}\"\n",
    "        for solution in examples['solution']\n",
    "    ]\n",
    "    # Concatenate inputs and targets\n",
    "    full_texts = [inp + tgt for inp, tgt in zip(inputs, targets)]\n",
    "    # Tokenize the concatenated texts\n",
    "    model_inputs = tokenizer(\n",
    "        full_texts,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"longest\",  # Use dynamic padding\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Create labels by cloning input IDs\n",
    "    labels = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    # Mask input tokens in labels\n",
    "    for i in range(len(labels)):\n",
    "        input_ids = tokenizer(inputs[i], add_special_tokens=False).input_ids\n",
    "        input_len = len(input_ids)\n",
    "        labels[i][:input_len] = -100  # Mask the input tokens\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2906852c",
   "metadata": {
    "_cell_guid": "7813b7e4-9e2c-4b60-aebf-aabe489615f0",
    "_uuid": "a579b1dd-8573-4ca8-85cf-37ed55b4953f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:17:17.745259Z",
     "iopub.status.busy": "2024-12-11T18:17:17.744946Z",
     "iopub.status.idle": "2024-12-11T18:17:17.749015Z",
     "shell.execute_reply": "2024-12-11T18:17:17.748153Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012267,
     "end_time": "2024-12-11T18:17:17.750697",
     "exception": false,
     "start_time": "2024-12-11T18:17:17.738430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # For causal language modeling\n",
    "    pad_to_multiple_of=8  # For faster GPU performance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b149488",
   "metadata": {
    "_cell_guid": "30c98053-f7dd-4419-93b8-ca1fe34a8e42",
    "_uuid": "7097f25d-da11-40a9-bc53-e092dffa2c01",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:17:17.762458Z",
     "iopub.status.busy": "2024-12-11T18:17:17.762132Z",
     "iopub.status.idle": "2024-12-11T18:17:21.258100Z",
     "shell.execute_reply": "2024-12-11T18:17:21.257282Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.504039,
     "end_time": "2024-12-11T18:17:21.259795",
     "exception": false,
     "start_time": "2024-12-11T18:17:17.755756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb31ac02822d428daeba2b711a18c9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MATH.py:   0%|          | 0.00/4.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a117f3adc14ba5887d6c8bba6282a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/algebra_train.jsonl:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda484726384425ca666903c68f5e427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ata/counting_and_probability_train.jsonl:   0%|          | 0.00/707k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accec8751e32467d8b11fdb61996427d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/geometry_train.jsonl:   0%|          | 0.00/1.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec23e547d67d461892b4ea48195389e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/intermediate_algebra_train.jsonl:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764e525833d14449ac566744f6ffa5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/number_theory_train.jsonl:   0%|          | 0.00/639k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83bb4ed2fef43fbad361afba97c6fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/prealgebra_train.jsonl:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09608d15e62441bcbd7cbd499cac0794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/precalculus_train.jsonl:   0%|          | 0.00/903k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e6f180a78244c7bfc450b57f9669a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/algebra_test.jsonl:   0%|          | 0.00/706k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a625c2279435406680a2fa17c89500b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/counting_and_probability_test.jsonl:   0%|          | 0.00/377k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f922a89a7b204a1ab083d23ef2cf07ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/geometry_test.jsonl:   0%|          | 0.00/562k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cb61cb77114e32a8d5f7c22e457514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/intermediate_algebra_test.jsonl:   0%|          | 0.00/860k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4028f811f2fb4368b8f5fe9e402b6113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/number_theory_test.jsonl:   0%|          | 0.00/376k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cfa2f58ea8491ab911fd2b1714c8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/prealgebra_test.jsonl:   0%|          | 0.00/553k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbd4c32be1441b1b3d2e9e7943cc1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/precalculus_test.jsonl:   0%|          | 0.00/614k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d608b4ec7c9441d5ad7eb8dc666b2b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acf4be1eb4b4d7b82b82c2198c04b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5935a9f75ff04a5f8184daf1591a747d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Maxwell-Jia/MATH\",trust_remote_code=True)\n",
    "dataset['train'] = dataset['train'].filter(\n",
    "        lambda x: x['level'] != f\"Level ?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80719635",
   "metadata": {
    "_cell_guid": "c8171379-799a-410f-9d17-06107b6ff0f0",
    "_uuid": "faac289a-5f57-4e41-b8a9-c61d875cf621",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:17:21.274941Z",
     "iopub.status.busy": "2024-12-11T18:17:21.274625Z",
     "iopub.status.idle": "2024-12-11T18:17:29.215349Z",
     "shell.execute_reply": "2024-12-11T18:17:29.214299Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.95019,
     "end_time": "2024-12-11T18:17:29.217375",
     "exception": false,
     "start_time": "2024-12-11T18:17:21.267185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 180355072 (19.40% of total), Total : 929632256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 90177536 (10.74% of total), Total : 839454720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 45088768 (5.68% of total), Total : 794365952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 22544384 (2.92% of total), Total : 771821568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 22544384 (2.92% of total), Total : 771821568\n"
     ]
    }
   ],
   "source": [
    "for lci in lora_config.keys():\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = get_peft_model(model, lora_config[lci])\n",
    "    trainable_params = 0\n",
    "    total_params = 0\n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()\n",
    "        total_params += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    print(f\"Trainable parameters: {trainable_params} ({100 * trainable_params / total_params:.2f}% of total), Total : {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e0dd02",
   "metadata": {
    "_cell_guid": "a4010029-1756-4444-b9f2-dbc6c4a72b80",
    "_uuid": "2033f18b-6bff-4271-b3bf-9394bc1a21f3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T18:17:29.238440Z",
     "iopub.status.busy": "2024-12-11T18:17:29.238098Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-12-11T18:17:29.228062",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for Level 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1e7c30c7464bac98e2eea66ddee35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acb984dd92d4802ba1ebadcc7749ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 564\n",
      "Number of test samples: 437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e221c8a60647a4a92911d134323ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd70d256ebc141f4835cb6de1a5314fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='705' max='705' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [705/705 16:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.042500</td>\n",
       "      <td>0.699341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.848444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.923881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>1.046901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f563a3cf5de4a92879a570acc5bf42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3242d1245c3b4fcb85e5834b660517f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/1.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55/55 00:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation results: {'eval_loss': 0.9238811731338501, 'eval_runtime': 52.403, 'eval_samples_per_second': 8.339, 'eval_steps_per_second': 1.05, 'epoch': 5.0}\n",
      "[{'loss': 1.0425, 'grad_norm': 2.7326579093933105, 'learning_rate': 4.771293375394322e-05, 'epoch': 0.7092198581560284, 'step': 100}, {'eval_loss': 0.6993407011032104, 'eval_runtime': 51.2407, 'eval_samples_per_second': 8.528, 'eval_steps_per_second': 1.073, 'epoch': 1.0638297872340425, 'step': 150}, {'loss': 0.5545, 'grad_norm': 2.8890068531036377, 'learning_rate': 3.982649842271294e-05, 'epoch': 1.4184397163120568, 'step': 200}, {'loss': 0.4037, 'grad_norm': 3.034909963607788, 'learning_rate': 3.194006309148265e-05, 'epoch': 2.127659574468085, 'step': 300}, {'eval_loss': 0.8484441637992859, 'eval_runtime': 54.3257, 'eval_samples_per_second': 8.044, 'eval_steps_per_second': 1.012, 'epoch': 2.127659574468085, 'step': 300}, {'loss': 0.2303, 'grad_norm': 2.743929147720337, 'learning_rate': 2.405362776025237e-05, 'epoch': 2.8368794326241136, 'step': 400}, {'eval_loss': 0.9238811731338501, 'eval_runtime': 55.4064, 'eval_samples_per_second': 7.887, 'eval_steps_per_second': 0.993, 'epoch': 3.1914893617021276, 'step': 450}, {'loss': 0.1544, 'grad_norm': 1.8299005031585693, 'learning_rate': 1.616719242902208e-05, 'epoch': 3.546099290780142, 'step': 500}, {'loss': 0.1059, 'grad_norm': 0.8745108842849731, 'learning_rate': 8.280757097791798e-06, 'epoch': 4.25531914893617, 'step': 600}, {'eval_loss': 1.0469008684158325, 'eval_runtime': 52.9169, 'eval_samples_per_second': 8.258, 'eval_steps_per_second': 1.039, 'epoch': 4.25531914893617, 'step': 600}, {'loss': 0.0774, 'grad_norm': 1.2600290775299072, 'learning_rate': 3.943217665615142e-07, 'epoch': 4.964539007092198, 'step': 700}, {'train_runtime': 991.7305, 'train_samples_per_second': 2.844, 'train_steps_per_second': 0.711, 'total_flos': 9992826897039360.0, 'train_loss': 0.3648715818181951, 'epoch': 5.0, 'step': 705}, {'eval_loss': 0.9238811731338501, 'eval_runtime': 52.403, 'eval_samples_per_second': 8.339, 'eval_steps_per_second': 1.05, 'epoch': 5.0, 'step': 705}]\n",
      "\n",
      "Starting training for Level 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight']\n",
      "  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d04854efa1f4a61a06bfd083e51b15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8756045f104fa3841e8893ff439441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1912\n",
      "Number of test samples: 1331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb4bcc46ee6420095920341a9e44d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d325bce8d545deb6ac951f94a40836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='2390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 750/2390 26:30 < 58:06, 0.47 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.311400</td>\n",
       "      <td>0.748185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.711647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>0.688194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.697540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.690611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb34a8405ee47d7a9a2b8298b4e7adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8020d3ec4841248d5d2732ca5a9833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/361M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [167/167 02:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation results: {'eval_loss': 0.6881941556930542, 'eval_runtime': 162.6619, 'eval_samples_per_second': 8.183, 'eval_steps_per_second': 1.027, 'epoch': 1.5690376569037658}\n",
      "[{'loss': 1.3114, 'grad_norm': 2.0684597492218018, 'learning_rate': 2.092050209205021e-05, 'epoch': 0.20920502092050208, 'step': 100}, {'eval_loss': 0.7481848001480103, 'eval_runtime': 155.7354, 'eval_samples_per_second': 8.547, 'eval_steps_per_second': 1.072, 'epoch': 0.3138075313807531, 'step': 150}, {'loss': 0.7641, 'grad_norm': 1.809200406074524, 'learning_rate': 4.184100418410042e-05, 'epoch': 0.41841004184100417, 'step': 200}, {'loss': 0.6916, 'grad_norm': 1.6641292572021484, 'learning_rate': 4.8582054858205486e-05, 'epoch': 0.6276150627615062, 'step': 300}, {'eval_loss': 0.711646556854248, 'eval_runtime': 155.9352, 'eval_samples_per_second': 8.536, 'eval_steps_per_second': 1.071, 'epoch': 0.6276150627615062, 'step': 300}, {'loss': 0.6997, 'grad_norm': 1.4930295944213867, 'learning_rate': 4.6257554625755466e-05, 'epoch': 0.8368200836820083, 'step': 400}, {'eval_loss': 0.6881941556930542, 'eval_runtime': 159.7767, 'eval_samples_per_second': 8.33, 'eval_steps_per_second': 1.045, 'epoch': 0.9414225941422594, 'step': 450}, {'loss': 0.6408, 'grad_norm': 1.9235706329345703, 'learning_rate': 4.393305439330544e-05, 'epoch': 1.0460251046025104, 'step': 500}, {'loss': 0.5018, 'grad_norm': 1.9497061967849731, 'learning_rate': 4.160855416085542e-05, 'epoch': 1.2552301255230125, 'step': 600}, {'eval_loss': 0.6975404620170593, 'eval_runtime': 162.0858, 'eval_samples_per_second': 8.212, 'eval_steps_per_second': 1.03, 'epoch': 1.2552301255230125, 'step': 600}, {'loss': 0.5245, 'grad_norm': 1.7506921291351318, 'learning_rate': 3.9284053928405394e-05, 'epoch': 1.4644351464435146, 'step': 700}, {'eval_loss': 0.690610945224762, 'eval_runtime': 161.9928, 'eval_samples_per_second': 8.216, 'eval_steps_per_second': 1.031, 'epoch': 1.5690376569037658, 'step': 750}, {'train_runtime': 1591.7679, 'train_samples_per_second': 6.006, 'train_steps_per_second': 1.501, 'total_flos': 9799590739968000.0, 'train_loss': 0.7181881383260091, 'epoch': 1.5690376569037658, 'step': 750}, {'eval_loss': 0.6881941556930542, 'eval_runtime': 162.6619, 'eval_samples_per_second': 8.183, 'eval_steps_per_second': 1.027, 'epoch': 1.5690376569037658, 'step': 750}]\n",
      "\n",
      "Starting training for Level 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight']\n",
      "  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aa053acba047c3bb61cdbbc3f0f8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ac08746e58417c847d64157a8cf4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 3504\n",
      "Number of test samples: 2462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23502afbcc4f40eaaa76e34045e4fdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3504 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cb8001b25f4ae5a22500c5ed180ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1950' max='4380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1950/4380 1:37:43 < 2:01:54, 0.33 it/s, Epoch 2/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.586000</td>\n",
       "      <td>0.888161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>0.752683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.734378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.715873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.700728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.705863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.561200</td>\n",
       "      <td>0.695691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.695835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.553600</td>\n",
       "      <td>0.691401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.686418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.683345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.716508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.729499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529693fe21047fbabb234bc7f61ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/180M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d5a669fa9f45f7a9ed85684d17450b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f96196ffed486cbdcc07d417462c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 04:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation results: {'eval_loss': 0.6914014220237732, 'eval_runtime': 294.9568, 'eval_samples_per_second': 8.347, 'eval_steps_per_second': 1.044, 'epoch': 2.2260273972602738}\n",
      "[{'loss': 1.586, 'grad_norm': 1.680282711982727, 'learning_rate': 1.1415525114155251e-05, 'epoch': 0.1141552511415525, 'step': 100}, {'eval_loss': 0.8881610035896301, 'eval_runtime': 294.084, 'eval_samples_per_second': 8.372, 'eval_steps_per_second': 1.047, 'epoch': 0.17123287671232876, 'step': 150}, {'loss': 0.869, 'grad_norm': 1.672010064125061, 'learning_rate': 2.2831050228310503e-05, 'epoch': 0.228310502283105, 'step': 200}, {'loss': 0.7648, 'grad_norm': 1.6577465534210205, 'learning_rate': 3.424657534246575e-05, 'epoch': 0.3424657534246575, 'step': 300}, {'eval_loss': 0.7526830434799194, 'eval_runtime': 294.4123, 'eval_samples_per_second': 8.362, 'eval_steps_per_second': 1.046, 'epoch': 0.3424657534246575, 'step': 300}, {'loss': 0.7148, 'grad_norm': 1.4545058012008667, 'learning_rate': 4.5662100456621006e-05, 'epoch': 0.45662100456621, 'step': 400}, {'eval_loss': 0.7343775629997253, 'eval_runtime': 294.4699, 'eval_samples_per_second': 8.361, 'eval_steps_per_second': 1.046, 'epoch': 0.5136986301369864, 'step': 450}, {'loss': 0.7051, 'grad_norm': 1.2586015462875366, 'learning_rate': 4.9213597158802636e-05, 'epoch': 0.5707762557077626, 'step': 500}, {'loss': 0.6795, 'grad_norm': 1.2179884910583496, 'learning_rate': 4.794520547945205e-05, 'epoch': 0.684931506849315, 'step': 600}, {'eval_loss': 0.7158730626106262, 'eval_runtime': 285.6226, 'eval_samples_per_second': 8.62, 'eval_steps_per_second': 1.078, 'epoch': 0.684931506849315, 'step': 600}, {'loss': 0.6911, 'grad_norm': 1.1722301244735718, 'learning_rate': 4.667681380010147e-05, 'epoch': 0.7990867579908676, 'step': 700}, {'eval_loss': 0.7007279992103577, 'eval_runtime': 294.002, 'eval_samples_per_second': 8.374, 'eval_steps_per_second': 1.048, 'epoch': 0.8561643835616438, 'step': 750}, {'loss': 0.6674, 'grad_norm': 1.1134378910064697, 'learning_rate': 4.5408422120750886e-05, 'epoch': 0.91324200913242, 'step': 800}, {'loss': 0.6454, 'grad_norm': 1.041154384613037, 'learning_rate': 4.41400304414003e-05, 'epoch': 1.0273972602739727, 'step': 900}, {'eval_loss': 0.7058629989624023, 'eval_runtime': 294.1965, 'eval_samples_per_second': 8.369, 'eval_steps_per_second': 1.047, 'epoch': 1.0273972602739727, 'step': 900}, {'loss': 0.5612, 'grad_norm': 1.2809343338012695, 'learning_rate': 4.287163876204972e-05, 'epoch': 1.1415525114155252, 'step': 1000}, {'eval_loss': 0.6956906318664551, 'eval_runtime': 294.5108, 'eval_samples_per_second': 8.36, 'eval_steps_per_second': 1.046, 'epoch': 1.1986301369863013, 'step': 1050}, {'loss': 0.5749, 'grad_norm': 1.3561667203903198, 'learning_rate': 4.160324708269914e-05, 'epoch': 1.2557077625570776, 'step': 1100}, {'loss': 0.5788, 'grad_norm': 1.0495189428329468, 'learning_rate': 4.0334855403348554e-05, 'epoch': 1.36986301369863, 'step': 1200}, {'eval_loss': 0.695834755897522, 'eval_runtime': 293.9171, 'eval_samples_per_second': 8.377, 'eval_steps_per_second': 1.048, 'epoch': 1.36986301369863, 'step': 1200}, {'loss': 0.5536, 'grad_norm': 1.1591973304748535, 'learning_rate': 3.906646372399797e-05, 'epoch': 1.4840182648401825, 'step': 1300}, {'eval_loss': 0.6914014220237732, 'eval_runtime': 292.4335, 'eval_samples_per_second': 8.419, 'eval_steps_per_second': 1.053, 'epoch': 1.541095890410959, 'step': 1350}, {'loss': 0.5503, 'grad_norm': 1.238006591796875, 'learning_rate': 3.779807204464739e-05, 'epoch': 1.5981735159817352, 'step': 1400}, {'loss': 0.5621, 'grad_norm': 1.0140610933303833, 'learning_rate': 3.6529680365296805e-05, 'epoch': 1.7123287671232876, 'step': 1500}, {'eval_loss': 0.6864176988601685, 'eval_runtime': 294.2199, 'eval_samples_per_second': 8.368, 'eval_steps_per_second': 1.047, 'epoch': 1.7123287671232876, 'step': 1500}, {'loss': 0.5435, 'grad_norm': 1.2826935052871704, 'learning_rate': 3.526128868594622e-05, 'epoch': 1.82648401826484, 'step': 1600}, {'eval_loss': 0.6833446025848389, 'eval_runtime': 293.8591, 'eval_samples_per_second': 8.378, 'eval_steps_per_second': 1.048, 'epoch': 1.8835616438356164, 'step': 1650}, {'loss': 0.5654, 'grad_norm': 1.4018515348434448, 'learning_rate': 3.399289700659564e-05, 'epoch': 1.9406392694063928, 'step': 1700}, {'loss': 0.5002, 'grad_norm': 1.482837200164795, 'learning_rate': 3.2724505327245055e-05, 'epoch': 2.0547945205479454, 'step': 1800}, {'eval_loss': 0.7165083289146423, 'eval_runtime': 289.4264, 'eval_samples_per_second': 8.506, 'eval_steps_per_second': 1.064, 'epoch': 2.0547945205479454, 'step': 1800}, {'loss': 0.4372, 'grad_norm': 1.4618955850601196, 'learning_rate': 3.145611364789447e-05, 'epoch': 2.1689497716894977, 'step': 1900}, {'eval_loss': 0.7294990420341492, 'eval_runtime': 293.3681, 'eval_samples_per_second': 8.392, 'eval_steps_per_second': 1.05, 'epoch': 2.2260273972602738, 'step': 1950}, {'train_runtime': 5864.7399, 'train_samples_per_second': 2.987, 'train_steps_per_second': 0.747, 'total_flos': 2.4398536900608e+16, 'train_loss': 0.6646372653276492, 'epoch': 2.2260273972602738, 'step': 1950}, {'eval_loss': 0.6914014220237732, 'eval_runtime': 294.9568, 'eval_samples_per_second': 8.347, 'eval_steps_per_second': 1.044, 'epoch': 2.2260273972602738, 'step': 1950}]\n",
      "\n",
      "Starting training for Level 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight']\n",
      "  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815e8a207d044e568551fb59846522c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf40f38e79b74127b4039d4ca1a193ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5194\n",
      "Number of test samples: 3676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a8b358ca4d4adaa4f5f12f929f71e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063c2d6adf4f4f35b730276640c7edc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2850' max='6495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2850/6495 2:58:18 < 3:48:12, 0.27 it/s, Epoch 2/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.822800</td>\n",
       "      <td>0.942038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>0.865910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>0.770244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.729400</td>\n",
       "      <td>0.755498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.746751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.736536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.682100</td>\n",
       "      <td>0.725999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.682300</td>\n",
       "      <td>0.721724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.718246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.590500</td>\n",
       "      <td>0.716710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.598700</td>\n",
       "      <td>0.712785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.619100</td>\n",
       "      <td>0.709756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.595300</td>\n",
       "      <td>0.706838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.598500</td>\n",
       "      <td>0.702438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.609500</td>\n",
       "      <td>0.700153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.698098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.695428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.716086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.715344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e923b3f0d1a243b1a559f34825c587ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/90.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cbe8bd9c744a1793cd7d34550edfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6850bdd244e343fbad9e63a62738bc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 06:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation results: {'eval_loss': 0.7001526951789856, 'eval_runtime': 404.716, 'eval_samples_per_second': 9.083, 'eval_steps_per_second': 1.137, 'epoch': 2.1939953810623556}\n",
      "[{'loss': 1.8228, 'grad_norm': 2.058830738067627, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.07698229407236336, 'step': 100}, {'eval_loss': 0.9420379996299744, 'eval_runtime': 409.3385, 'eval_samples_per_second': 8.98, 'eval_steps_per_second': 1.124, 'epoch': 0.11547344110854503, 'step': 150}, {'loss': 0.923, 'grad_norm': 1.4816007614135742, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.15396458814472672, 'step': 200}, {'loss': 0.8683, 'grad_norm': 1.114583969116211, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.23094688221709006, 'step': 300}, {'eval_loss': 0.8659098148345947, 'eval_runtime': 429.2293, 'eval_samples_per_second': 8.564, 'eval_steps_per_second': 1.072, 'epoch': 0.23094688221709006, 'step': 300}, {'loss': 0.7695, 'grad_norm': 1.6131666898727417, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.30792917628945343, 'step': 400}, {'eval_loss': 0.770244300365448, 'eval_runtime': 417.2668, 'eval_samples_per_second': 8.81, 'eval_steps_per_second': 1.102, 'epoch': 0.3464203233256351, 'step': 450}, {'loss': 0.7336, 'grad_norm': 0.9973576664924622, 'learning_rate': 3.846153846153846e-05, 'epoch': 0.3849114703618168, 'step': 500}, {'loss': 0.7294, 'grad_norm': 1.3565261363983154, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.4618937644341801, 'step': 600}, {'eval_loss': 0.7554978728294373, 'eval_runtime': 436.7378, 'eval_samples_per_second': 8.417, 'eval_steps_per_second': 1.053, 'epoch': 0.4618937644341801, 'step': 600}, {'loss': 0.6953, 'grad_norm': 1.169132947921753, 'learning_rate': 4.957228400342173e-05, 'epoch': 0.5388760585065435, 'step': 700}, {'eval_loss': 0.7467510104179382, 'eval_runtime': 434.0098, 'eval_samples_per_second': 8.47, 'eval_steps_per_second': 1.06, 'epoch': 0.5773672055427251, 'step': 750}, {'loss': 0.7048, 'grad_norm': 0.7827513217926025, 'learning_rate': 4.871685201026518e-05, 'epoch': 0.6158583525789069, 'step': 800}, {'loss': 0.6895, 'grad_norm': 0.9658424854278564, 'learning_rate': 4.7861420017108646e-05, 'epoch': 0.6928406466512702, 'step': 900}, {'eval_loss': 0.7365363836288452, 'eval_runtime': 436.474, 'eval_samples_per_second': 8.422, 'eval_steps_per_second': 1.054, 'epoch': 0.6928406466512702, 'step': 900}, {'loss': 0.6821, 'grad_norm': 1.3084155321121216, 'learning_rate': 4.70059880239521e-05, 'epoch': 0.7698229407236336, 'step': 1000}, {'eval_loss': 0.7259991765022278, 'eval_runtime': 432.9058, 'eval_samples_per_second': 8.491, 'eval_steps_per_second': 1.063, 'epoch': 0.8083140877598153, 'step': 1050}, {'loss': 0.6963, 'grad_norm': 1.0965921878814697, 'learning_rate': 4.6150556030795554e-05, 'epoch': 0.8468052347959969, 'step': 1100}, {'loss': 0.6823, 'grad_norm': 0.8271883130073547, 'learning_rate': 4.5295124037639005e-05, 'epoch': 0.9237875288683602, 'step': 1200}, {'eval_loss': 0.7217240333557129, 'eval_runtime': 404.4751, 'eval_samples_per_second': 9.088, 'eval_steps_per_second': 1.137, 'epoch': 0.9237875288683602, 'step': 1200}, {'loss': 0.696, 'grad_norm': 1.140114188194275, 'learning_rate': 4.443969204448247e-05, 'epoch': 1.0007698229407236, 'step': 1300}, {'eval_loss': 0.7182462215423584, 'eval_runtime': 406.1632, 'eval_samples_per_second': 9.051, 'eval_steps_per_second': 1.133, 'epoch': 1.0392609699769053, 'step': 1350}, {'loss': 0.6111, 'grad_norm': 1.291319727897644, 'learning_rate': 4.358426005132592e-05, 'epoch': 1.077752117013087, 'step': 1400}, {'loss': 0.5905, 'grad_norm': 1.1123216152191162, 'learning_rate': 4.272882805816938e-05, 'epoch': 1.1547344110854503, 'step': 1500}, {'eval_loss': 0.716709554195404, 'eval_runtime': 406.2735, 'eval_samples_per_second': 9.048, 'eval_steps_per_second': 1.132, 'epoch': 1.1547344110854503, 'step': 1500}, {'loss': 0.5987, 'grad_norm': 1.1965298652648926, 'learning_rate': 4.1873396065012835e-05, 'epoch': 1.2317167051578137, 'step': 1600}, {'eval_loss': 0.7127854824066162, 'eval_runtime': 406.3172, 'eval_samples_per_second': 9.047, 'eval_steps_per_second': 1.132, 'epoch': 1.2702078521939955, 'step': 1650}, {'loss': 0.6246, 'grad_norm': 1.1025627851486206, 'learning_rate': 4.101796407185629e-05, 'epoch': 1.308698999230177, 'step': 1700}, {'loss': 0.6191, 'grad_norm': 1.1860860586166382, 'learning_rate': 4.016253207869974e-05, 'epoch': 1.3856812933025404, 'step': 1800}, {'eval_loss': 0.7097558975219727, 'eval_runtime': 406.6088, 'eval_samples_per_second': 9.041, 'eval_steps_per_second': 1.131, 'epoch': 1.3856812933025404, 'step': 1800}, {'loss': 0.5953, 'grad_norm': 1.0926424264907837, 'learning_rate': 3.93071000855432e-05, 'epoch': 1.4626635873749039, 'step': 1900}, {'eval_loss': 0.7068380117416382, 'eval_runtime': 405.9218, 'eval_samples_per_second': 9.056, 'eval_steps_per_second': 1.133, 'epoch': 1.5011547344110854, 'step': 1950}, {'loss': 0.6115, 'grad_norm': 1.0318191051483154, 'learning_rate': 3.845166809238666e-05, 'epoch': 1.539645881447267, 'step': 2000}, {'loss': 0.5985, 'grad_norm': 1.3462437391281128, 'learning_rate': 3.7596236099230116e-05, 'epoch': 1.6166281755196303, 'step': 2100}, {'eval_loss': 0.702437698841095, 'eval_runtime': 400.7011, 'eval_samples_per_second': 9.174, 'eval_steps_per_second': 1.148, 'epoch': 1.6166281755196303, 'step': 2100}, {'loss': 0.6095, 'grad_norm': 0.9768049716949463, 'learning_rate': 3.6740804106073567e-05, 'epoch': 1.6936104695919938, 'step': 2200}, {'eval_loss': 0.7001526951789856, 'eval_runtime': 406.0349, 'eval_samples_per_second': 9.053, 'eval_steps_per_second': 1.133, 'epoch': 1.7321016166281755, 'step': 2250}, {'loss': 0.5874, 'grad_norm': 1.0576826333999634, 'learning_rate': 3.5885372112917024e-05, 'epoch': 1.7705927636643572, 'step': 2300}, {'loss': 0.6129, 'grad_norm': 1.0046297311782837, 'learning_rate': 3.502994011976048e-05, 'epoch': 1.8475750577367207, 'step': 2400}, {'eval_loss': 0.698097825050354, 'eval_runtime': 397.5221, 'eval_samples_per_second': 9.247, 'eval_steps_per_second': 1.157, 'epoch': 1.8475750577367207, 'step': 2400}, {'loss': 0.6016, 'grad_norm': 1.3174242973327637, 'learning_rate': 3.417450812660394e-05, 'epoch': 1.924557351809084, 'step': 2500}, {'eval_loss': 0.6954284310340881, 'eval_runtime': 401.1549, 'eval_samples_per_second': 9.164, 'eval_steps_per_second': 1.147, 'epoch': 1.9630484988452657, 'step': 2550}, {'loss': 0.6043, 'grad_norm': 0.9912453293800354, 'learning_rate': 3.331907613344739e-05, 'epoch': 2.001539645881447, 'step': 2600}, {'loss': 0.5144, 'grad_norm': 1.210602879524231, 'learning_rate': 3.246364414029085e-05, 'epoch': 2.0785219399538106, 'step': 2700}, {'eval_loss': 0.7160857319831848, 'eval_runtime': 405.7948, 'eval_samples_per_second': 9.059, 'eval_steps_per_second': 1.134, 'epoch': 2.0785219399538106, 'step': 2700}, {'loss': 0.512, 'grad_norm': 1.3148276805877686, 'learning_rate': 3.1608212147134305e-05, 'epoch': 2.155504234026174, 'step': 2800}, {'eval_loss': 0.7153435349464417, 'eval_runtime': 406.3154, 'eval_samples_per_second': 9.047, 'eval_steps_per_second': 1.132, 'epoch': 2.1939953810623556, 'step': 2850}, {'train_runtime': 10699.6974, 'train_samples_per_second': 2.427, 'train_steps_per_second': 0.607, 'total_flos': 3.485764267750195e+16, 'train_loss': 0.695952048719975, 'epoch': 2.1939953810623556, 'step': 2850}, {'eval_loss': 0.7001526951789856, 'eval_runtime': 404.716, 'eval_samples_per_second': 9.083, 'eval_steps_per_second': 1.137, 'epoch': 2.1939953810623556, 'step': 2850}]\n",
      "\n",
      "Starting training for Level 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight']\n",
      "  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89daa73a41ed446eb094e316b14c95a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387604ca57324593a2aabcc82f97553c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 7498\n",
      "Number of test samples: 5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73d363082634efe8d767b5e385b9494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5007a87e864c04a7ba8b5d05cbefbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4050' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4050/9375 5:28:20 < 7:11:55, 0.21 it/s, Epoch 2/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.929300</td>\n",
       "      <td>0.987709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.901144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.864400</td>\n",
       "      <td>0.802649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.770800</td>\n",
       "      <td>0.784849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.775926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.774900</td>\n",
       "      <td>0.766913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.757107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.750670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.732700</td>\n",
       "      <td>0.742923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>0.738191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.733005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>0.728077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.730916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.728008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.727997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.722793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.721201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.718887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>0.717624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.717749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.713772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.713369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>0.710304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.708997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.658200</td>\n",
       "      <td>0.707851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.726464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>0.725077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368747a8dbdd4b42b8dbbb880494eea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/90.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ab33e0e12849be83bd9f94ed672340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a0156b89fc4a928de0ec02ec990133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 08:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation results: {'eval_loss': 0.7089974880218506, 'eval_runtime': 531.1182, 'eval_samples_per_second': 9.414, 'eval_steps_per_second': 1.177, 'epoch': 2.16}\n",
      "[{'loss': 1.9293, 'grad_norm': 1.916932225227356, 'learning_rate': 5.330490405117271e-06, 'epoch': 0.05333333333333334, 'step': 100}, {'eval_loss': 0.987708568572998, 'eval_runtime': 552.7718, 'eval_samples_per_second': 9.045, 'eval_steps_per_second': 1.131, 'epoch': 0.08, 'step': 150}, {'loss': 1.03, 'grad_norm': 1.2509994506835938, 'learning_rate': 1.0660980810234541e-05, 'epoch': 0.10666666666666667, 'step': 200}, {'loss': 0.9088, 'grad_norm': 1.4883673191070557, 'learning_rate': 1.5991471215351813e-05, 'epoch': 0.16, 'step': 300}, {'eval_loss': 0.9011439681053162, 'eval_runtime': 550.5185, 'eval_samples_per_second': 9.082, 'eval_steps_per_second': 1.135, 'epoch': 0.16, 'step': 300}, {'loss': 0.8644, 'grad_norm': 1.1280219554901123, 'learning_rate': 2.1321961620469083e-05, 'epoch': 0.21333333333333335, 'step': 400}, {'eval_loss': 0.8026491403579712, 'eval_runtime': 563.2997, 'eval_samples_per_second': 8.876, 'eval_steps_per_second': 1.11, 'epoch': 0.24, 'step': 450}, {'loss': 0.8179, 'grad_norm': 1.1128586530685425, 'learning_rate': 2.6652452025586356e-05, 'epoch': 0.26666666666666666, 'step': 500}, {'loss': 0.7708, 'grad_norm': 1.6162701845169067, 'learning_rate': 3.1982942430703626e-05, 'epoch': 0.32, 'step': 600}, {'eval_loss': 0.7848494052886963, 'eval_runtime': 592.5779, 'eval_samples_per_second': 8.438, 'eval_steps_per_second': 1.055, 'epoch': 0.32, 'step': 600}, {'loss': 0.7557, 'grad_norm': 1.4260151386260986, 'learning_rate': 3.73134328358209e-05, 'epoch': 0.37333333333333335, 'step': 700}, {'eval_loss': 0.7759262919425964, 'eval_runtime': 594.8648, 'eval_samples_per_second': 8.405, 'eval_steps_per_second': 1.051, 'epoch': 0.4, 'step': 750}, {'loss': 0.746, 'grad_norm': 1.2070178985595703, 'learning_rate': 4.2643923240938166e-05, 'epoch': 0.4266666666666667, 'step': 800}, {'loss': 0.7749, 'grad_norm': 1.4503165483474731, 'learning_rate': 4.7974413646055436e-05, 'epoch': 0.48, 'step': 900}, {'eval_loss': 0.7669129371643066, 'eval_runtime': 582.4256, 'eval_samples_per_second': 8.585, 'eval_steps_per_second': 1.073, 'epoch': 0.48, 'step': 900}, {'loss': 0.7504, 'grad_norm': 1.1841799020767212, 'learning_rate': 4.96325708190115e-05, 'epoch': 0.5333333333333333, 'step': 1000}, {'eval_loss': 0.7571074962615967, 'eval_runtime': 595.0455, 'eval_samples_per_second': 8.403, 'eval_steps_per_second': 1.05, 'epoch': 0.56, 'step': 1050}, {'loss': 0.7547, 'grad_norm': 0.9074656963348389, 'learning_rate': 4.903994310773972e-05, 'epoch': 0.5866666666666667, 'step': 1100}, {'loss': 0.7501, 'grad_norm': 1.046326994895935, 'learning_rate': 4.844731539646794e-05, 'epoch': 0.64, 'step': 1200}, {'eval_loss': 0.7506701350212097, 'eval_runtime': 567.6634, 'eval_samples_per_second': 8.808, 'eval_steps_per_second': 1.101, 'epoch': 0.64, 'step': 1200}, {'loss': 0.7327, 'grad_norm': 1.1976678371429443, 'learning_rate': 4.785468768519616e-05, 'epoch': 0.6933333333333334, 'step': 1300}, {'eval_loss': 0.7429226636886597, 'eval_runtime': 591.9342, 'eval_samples_per_second': 8.447, 'eval_steps_per_second': 1.056, 'epoch': 0.72, 'step': 1350}, {'loss': 0.7305, 'grad_norm': 1.1685575246810913, 'learning_rate': 4.726205997392438e-05, 'epoch': 0.7466666666666667, 'step': 1400}, {'loss': 0.7503, 'grad_norm': 1.0525577068328857, 'learning_rate': 4.66694322626526e-05, 'epoch': 0.8, 'step': 1500}, {'eval_loss': 0.7381910085678101, 'eval_runtime': 595.0631, 'eval_samples_per_second': 8.402, 'eval_steps_per_second': 1.05, 'epoch': 0.8, 'step': 1500}, {'loss': 0.7372, 'grad_norm': 0.8387598991394043, 'learning_rate': 4.6076804551380823e-05, 'epoch': 0.8533333333333334, 'step': 1600}, {'eval_loss': 0.7330053448677063, 'eval_runtime': 587.2875, 'eval_samples_per_second': 8.514, 'eval_steps_per_second': 1.064, 'epoch': 0.88, 'step': 1650}, {'loss': 0.7235, 'grad_norm': 0.8747836351394653, 'learning_rate': 4.5484176840109044e-05, 'epoch': 0.9066666666666666, 'step': 1700}, {'loss': 0.6973, 'grad_norm': 1.0599346160888672, 'learning_rate': 4.4891549128837265e-05, 'epoch': 0.96, 'step': 1800}, {'eval_loss': 0.7280768752098083, 'eval_runtime': 569.9927, 'eval_samples_per_second': 8.772, 'eval_steps_per_second': 1.097, 'epoch': 0.96, 'step': 1800}, {'loss': 0.7055, 'grad_norm': 1.001220941543579, 'learning_rate': 4.4298921417565486e-05, 'epoch': 1.0133333333333334, 'step': 1900}, {'eval_loss': 0.7309158444404602, 'eval_runtime': 566.8173, 'eval_samples_per_second': 8.821, 'eval_steps_per_second': 1.103, 'epoch': 1.04, 'step': 1950}, {'loss': 0.6673, 'grad_norm': 1.4375020265579224, 'learning_rate': 4.370629370629371e-05, 'epoch': 1.0666666666666667, 'step': 2000}, {'loss': 0.6554, 'grad_norm': 0.9644463658332825, 'learning_rate': 4.311366599502193e-05, 'epoch': 1.12, 'step': 2100}, {'eval_loss': 0.7280079126358032, 'eval_runtime': 567.1522, 'eval_samples_per_second': 8.816, 'eval_steps_per_second': 1.102, 'epoch': 1.12, 'step': 2100}, {'loss': 0.6335, 'grad_norm': 0.975211501121521, 'learning_rate': 4.252103828375015e-05, 'epoch': 1.1733333333333333, 'step': 2200}, {'eval_loss': 0.7279972434043884, 'eval_runtime': 579.9122, 'eval_samples_per_second': 8.622, 'eval_steps_per_second': 1.078, 'epoch': 1.2, 'step': 2250}, {'loss': 0.6772, 'grad_norm': 1.1362661123275757, 'learning_rate': 4.192841057247837e-05, 'epoch': 1.2266666666666666, 'step': 2300}, {'loss': 0.6601, 'grad_norm': 1.0369521379470825, 'learning_rate': 4.133578286120659e-05, 'epoch': 1.28, 'step': 2400}, {'eval_loss': 0.7227928042411804, 'eval_runtime': 567.3296, 'eval_samples_per_second': 8.813, 'eval_steps_per_second': 1.102, 'epoch': 1.28, 'step': 2400}, {'loss': 0.6693, 'grad_norm': 1.3084633350372314, 'learning_rate': 4.0743155149934817e-05, 'epoch': 1.3333333333333333, 'step': 2500}, {'eval_loss': 0.721200704574585, 'eval_runtime': 567.1249, 'eval_samples_per_second': 8.816, 'eval_steps_per_second': 1.102, 'epoch': 1.3599999999999999, 'step': 2550}, {'loss': 0.6299, 'grad_norm': 1.251150131225586, 'learning_rate': 4.015052743866303e-05, 'epoch': 1.3866666666666667, 'step': 2600}, {'loss': 0.6441, 'grad_norm': 1.0630919933319092, 'learning_rate': 3.955789972739126e-05, 'epoch': 1.44, 'step': 2700}, {'eval_loss': 0.7188869118690491, 'eval_runtime': 586.5654, 'eval_samples_per_second': 8.524, 'eval_steps_per_second': 1.066, 'epoch': 1.44, 'step': 2700}, {'loss': 0.6808, 'grad_norm': 1.2505143880844116, 'learning_rate': 3.896527201611947e-05, 'epoch': 1.4933333333333334, 'step': 2800}, {'eval_loss': 0.7176241278648376, 'eval_runtime': 594.2858, 'eval_samples_per_second': 8.413, 'eval_steps_per_second': 1.052, 'epoch': 1.52, 'step': 2850}, {'loss': 0.6385, 'grad_norm': 1.2138363122940063, 'learning_rate': 3.83726443048477e-05, 'epoch': 1.5466666666666666, 'step': 2900}, {'loss': 0.6432, 'grad_norm': 1.2938047647476196, 'learning_rate': 3.778001659357592e-05, 'epoch': 1.6, 'step': 3000}, {'eval_loss': 0.7177489995956421, 'eval_runtime': 594.9839, 'eval_samples_per_second': 8.404, 'eval_steps_per_second': 1.05, 'epoch': 1.6, 'step': 3000}, {'loss': 0.6475, 'grad_norm': 1.3504809141159058, 'learning_rate': 3.7187388882304134e-05, 'epoch': 1.6533333333333333, 'step': 3100}, {'eval_loss': 0.7137719392776489, 'eval_runtime': 595.1477, 'eval_samples_per_second': 8.401, 'eval_steps_per_second': 1.05, 'epoch': 1.6800000000000002, 'step': 3150}, {'loss': 0.6519, 'grad_norm': 1.1561152935028076, 'learning_rate': 3.659476117103236e-05, 'epoch': 1.7066666666666666, 'step': 3200}, {'loss': 0.6245, 'grad_norm': 1.0632452964782715, 'learning_rate': 3.6002133459760575e-05, 'epoch': 1.76, 'step': 3300}, {'eval_loss': 0.7133690118789673, 'eval_runtime': 580.0418, 'eval_samples_per_second': 8.62, 'eval_steps_per_second': 1.078, 'epoch': 1.76, 'step': 3300}, {'loss': 0.6274, 'grad_norm': 1.1721726655960083, 'learning_rate': 3.54095057484888e-05, 'epoch': 1.8133333333333335, 'step': 3400}, {'eval_loss': 0.7103043794631958, 'eval_runtime': 595.0772, 'eval_samples_per_second': 8.402, 'eval_steps_per_second': 1.05, 'epoch': 1.8399999999999999, 'step': 3450}, {'loss': 0.6499, 'grad_norm': 1.0821810960769653, 'learning_rate': 3.4816878037217024e-05, 'epoch': 1.8666666666666667, 'step': 3500}, {'loss': 0.6525, 'grad_norm': 0.9693533778190613, 'learning_rate': 3.4224250325945244e-05, 'epoch': 1.92, 'step': 3600}, {'eval_loss': 0.7089974880218506, 'eval_runtime': 571.4462, 'eval_samples_per_second': 8.75, 'eval_steps_per_second': 1.094, 'epoch': 1.92, 'step': 3600}, {'loss': 0.6582, 'grad_norm': 1.3254300355911255, 'learning_rate': 3.3631622614673465e-05, 'epoch': 1.9733333333333334, 'step': 3700}, {'eval_loss': 0.7078511714935303, 'eval_runtime': 551.2192, 'eval_samples_per_second': 9.071, 'eval_steps_per_second': 1.134, 'epoch': 2.0, 'step': 3750}, {'loss': 0.581, 'grad_norm': 1.2151790857315063, 'learning_rate': 3.303899490340168e-05, 'epoch': 2.026666666666667, 'step': 3800}, {'loss': 0.5364, 'grad_norm': 1.163899540901184, 'learning_rate': 3.2446367192129906e-05, 'epoch': 2.08, 'step': 3900}, {'eval_loss': 0.7264639735221863, 'eval_runtime': 554.2767, 'eval_samples_per_second': 9.021, 'eval_steps_per_second': 1.128, 'epoch': 2.08, 'step': 3900}, {'loss': 0.5595, 'grad_norm': 1.4180537462234497, 'learning_rate': 3.185373948085813e-05, 'epoch': 2.1333333333333333, 'step': 4000}, {'eval_loss': 0.7250769734382629, 'eval_runtime': 544.4679, 'eval_samples_per_second': 9.183, 'eval_steps_per_second': 1.148, 'epoch': 2.16, 'step': 4050}, {'train_runtime': 19701.5298, 'train_samples_per_second': 1.903, 'train_steps_per_second': 0.476, 'total_flos': 4.953969645531955e+16, 'train_loss': 0.7303078314698772, 'epoch': 2.16, 'step': 4050}, {'eval_loss': 0.7089974880218506, 'eval_runtime': 531.1182, 'eval_samples_per_second': 9.414, 'eval_steps_per_second': 1.177, 'epoch': 2.16, 'step': 4050}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   1%|          | 1/157 [00:47<2:03:45, 47.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   1%|▏         | 2/157 [01:40<2:11:00, 50.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   2%|▏         | 3/157 [02:27<2:06:21, 49.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   3%|▎         | 4/157 [03:20<2:09:11, 50.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   3%|▎         | 5/157 [03:53<1:52:22, 44.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   4%|▍         | 6/157 [04:43<1:56:01, 46.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   4%|▍         | 7/157 [05:26<1:52:48, 45.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   5%|▌         | 8/157 [06:10<1:50:57, 44.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   6%|▌         | 9/157 [06:53<1:49:10, 44.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   6%|▋         | 10/157 [07:37<1:47:55, 44.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   7%|▋         | 11/157 [08:20<1:46:36, 43.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   8%|▊         | 12/157 [09:28<2:03:43, 51.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   8%|▊         | 13/157 [09:43<1:36:26, 40.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:   9%|▉         | 14/157 [10:27<1:38:24, 41.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  10%|▉         | 15/157 [11:32<1:54:36, 48.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  10%|█         | 16/157 [12:15<1:50:23, 46.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  11%|█         | 17/157 [13:01<1:48:27, 46.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  11%|█▏        | 18/157 [13:44<1:45:47, 45.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  12%|█▏        | 19/157 [14:52<2:00:20, 52.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  13%|█▎        | 20/157 [15:36<1:53:18, 49.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  13%|█▎        | 21/157 [16:08<1:40:39, 44.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  14%|█▍        | 22/157 [16:57<1:43:00, 45.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  15%|█▍        | 23/157 [17:49<1:46:37, 47.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  15%|█▌        | 24/157 [18:33<1:43:13, 46.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  16%|█▌        | 25/157 [19:24<1:45:16, 47.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  17%|█▋        | 26/157 [19:57<1:34:32, 43.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  17%|█▋        | 27/157 [20:40<1:34:08, 43.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  18%|█▊        | 28/157 [21:23<1:32:42, 43.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  18%|█▊        | 29/157 [22:06<1:31:57, 43.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  19%|█▉        | 30/157 [22:23<1:14:43, 35.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  20%|█▉        | 31/157 [23:07<1:19:29, 37.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  20%|██        | 32/157 [23:50<1:22:23, 39.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  21%|██        | 33/157 [24:35<1:24:59, 41.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  22%|██▏       | 34/157 [25:21<1:27:26, 42.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  22%|██▏       | 35/157 [26:05<1:27:30, 43.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  23%|██▎       | 36/157 [26:48<1:26:59, 43.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  24%|██▎       | 37/157 [27:39<1:30:33, 45.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  24%|██▍       | 38/157 [28:09<1:21:02, 40.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  25%|██▍       | 39/157 [28:59<1:25:43, 43.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  25%|██▌       | 40/157 [29:51<1:29:58, 46.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  26%|██▌       | 41/157 [30:24<1:21:09, 41.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  27%|██▋       | 42/157 [31:29<1:33:44, 48.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  27%|██▋       | 43/157 [32:13<1:30:08, 47.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  28%|██▊       | 44/157 [33:09<1:34:13, 50.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  29%|██▊       | 45/157 [33:52<1:29:24, 47.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  29%|██▉       | 46/157 [34:45<1:31:31, 49.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  30%|██▉       | 47/157 [35:33<1:29:54, 49.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  31%|███       | 48/157 [36:48<1:43:29, 56.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  31%|███       | 49/157 [37:37<1:38:07, 54.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  32%|███▏      | 50/157 [38:26<1:34:26, 52.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  32%|███▏      | 51/157 [39:12<1:29:22, 50.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  33%|███▎      | 52/157 [39:59<1:26:51, 49.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  34%|███▍      | 53/157 [40:57<1:30:30, 52.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  34%|███▍      | 54/157 [41:48<1:28:56, 51.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  35%|███▌      | 55/157 [42:35<1:25:49, 50.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating Level 5:  36%|███▌      | 56/157 [43:26<1:24:58, 50.48s/it]"
     ]
    }
   ],
   "source": [
    "for level in range(1, 6):\n",
    "    print(f\"\\nStarting training for Level {level}\")\n",
    "\n",
    "    if level == 1:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            token=token,\n",
    "        )\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        lc = lora_config[\"lora_config1\"]\n",
    "        model = get_peft_model(model, lc)\n",
    "\n",
    "    else:\n",
    "        # Load tokenizer and model from previous level\n",
    "        prev_level = level - 1\n",
    "        prev_model_path = os.path.join(save_dir, f\"rank_llama_level_{prev_level}\")\n",
    "        \n",
    "        model = PeftModel.from_pretrained(\n",
    "        model=model,\n",
    "        model_id = prev_model_path,\n",
    "        peft_config=bnb_config,\n",
    "        device_map=\"auto\")\n",
    "        \n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        if level == 2:\n",
    "            lc = lora_config[\"lora_config2\"]\n",
    "            model = get_peft_model(model, lc)\n",
    "        if level == 3:\n",
    "            lc = lora_config[\"lora_config3\"]\n",
    "            model = get_peft_model(model, lc)\n",
    "        if level == 4:\n",
    "            lc = lora_config[\"lora_config4\"]\n",
    "            model = get_peft_model(model, lc)\n",
    "        if level == 5:\n",
    "            lc = lora_config[\"lora_config5\"]\n",
    "            model = get_peft_model(model, lc)       \n",
    "        tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    # Filter the dataset by current level\n",
    "    level_train = dataset['train'].filter(\n",
    "        lambda x: x['level'] <= f\"Level {level}\"\n",
    "    )\n",
    "    level_test = dataset['test'].filter(\n",
    "        lambda x: x['level'] <= f\"Level {level}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Number of training samples: {len(level_train)}\")\n",
    "    print(f\"Number of test samples: {len(level_test)}\")\n",
    "    \n",
    "#     # Combine with previous levels' data if applicable\n",
    "#     if level > 1:\n",
    "#         replay_fraction = 0.1  # Adjust as needed\n",
    "#         previous_levels_train = dataset['train'].filter(\n",
    "#             lambda x: int(x['level'].split()[-1]) < level\n",
    "#         ).shuffle(seed).select(range(int(len(level_train)*replay_fraction)))\n",
    "#         level_train = concatenate_datasets([level_train, previous_levels_train])\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    level_train = level_train.map(preprocess_function, batched=True)\n",
    "    level_test = level_test.map(preprocess_function, batched=True)\n",
    "    \n",
    "#     level_train = level_train.select(range(5))\n",
    "#     level_test = level_test.select(range(2))\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=os.path.join(save_dir, f\"rank_level_overall\"),\n",
    "      per_device_train_batch_size=4,\n",
    "      gradient_accumulation_steps=1,\n",
    "      warmup_ratio=0.1,\n",
    "      num_train_epochs=5,\n",
    "      learning_rate=5e-5,\n",
    "      fp16=True,  # Use bf16 precision\n",
    "      logging_steps=100,\n",
    "      optim=\"paged_adamw_8bit\",\n",
    "      evaluation_strategy=\"steps\",\n",
    "      eval_steps=150,\n",
    "      save_steps=450,\n",
    "      save_total_limit=2,\n",
    "      report_to=\"none\",  # Change to \"wandb\" if using Weights & Biases\n",
    "      run_name=f\"llama_FineTuning_Level_overall\",\n",
    "        load_best_model_at_end=True,  # Load the best model at the end\n",
    "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to select the best model\n",
    "    greater_is_better=False,\n",
    "        ddp_find_unused_parameters=False,\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2,  # Stop training if no improvement after 2 evaluations\n",
    "    )\n",
    "    \n",
    "    # Initialize the trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=level_train,\n",
    "        eval_dataset=level_test,\n",
    "        peft_config=lc,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[early_stopping_callback],\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    \n",
    "    # Save the model\n",
    "    model_save_path = os.path.join(save_dir, f\"rank_llama_level_{level}\")\n",
    "    model.save_pretrained(model_save_path,save_embedding_layers=True)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "    model.push_to_hub(f\"e3_mwp_sft_llama3.21b_level_{level}\", use_auth_token=token)\n",
    "    tokenizer.push_to_hub(f\"e3_mwp_sft_llama3.21b_level_{level}\", use_auth_token=token)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"Overall evaluation results: {results}\")\n",
    "    \n",
    "    print(trainer.state.log_history)\n",
    "\n",
    "    if level == 5:\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        test_samples = []\n",
    "        for idx in range(len(level_test)):\n",
    "            sample = level_test[idx]\n",
    "            input_text = (\n",
    "                f\"<|begin_of_text|><|start_header_id|>system <|end_header_id|>\"\n",
    "                \"You are an expert math assistant<|eot_id|><|start_header_id|>user <|end_header_id|>\"\n",
    "                f\"Solve the following math problem: {sample['problem']}\\n\"\n",
    "                \"Show all intermediate steps and please mandatorily include the final answer in LaTeX format in a box like \\\\boxed{{}}.\"\n",
    "                \"<|eot_id|><|start_header_id|> assistant <|end_header_id|>\"\n",
    "            )\n",
    "            test_samples.append({\n",
    "                \"input_text\": input_text,\n",
    "                \"problem\": sample['problem'],\n",
    "                \"level\": sample['level'],\n",
    "                \"type\": sample['type'],\n",
    "                \"ground_truth\": sample['solution']\n",
    "            })\n",
    "            \n",
    "        def collate_fn(batch):\n",
    "            input_texts = [sample['input_text'] for sample in batch]\n",
    "            model_inputs = tokenizer(\n",
    "                input_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=1024,  # Adjust as needed\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            model_inputs = {k: v.to(model.device) for k, v in model_inputs.items()}\n",
    "            return model_inputs, batch\n",
    "    \n",
    "        batch_size = 32  # Adjust based on your GPU memory\n",
    "        test_dataloader = DataLoader(test_samples, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "        results_list = []\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for batch_idx, (model_inputs, batch_samples) in enumerate(tqdm(test_dataloader, desc=f\"Evaluating Level {level}\")):\n",
    "            current_batch_size = model_inputs['input_ids'].size(0)\n",
    "            # Generate predictions\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    output_ids = model.generate(\n",
    "                        input_ids=model_inputs['input_ids'],\n",
    "                        attention_mask=model_inputs['attention_mask'],\n",
    "                        max_new_tokens=512,  \n",
    "                        do_sample=False,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.pad_token_id\n",
    "                    )\n",
    "                # Decode the outputs\n",
    "                for i in range(current_batch_size):\n",
    "                    predicted_text = tokenizer.decode(output_ids[i], skip_special_tokens=True)\n",
    "                    # Store the results\n",
    "                    results_list.append({\n",
    "                        \"problem\": batch_samples[i]['problem'],\n",
    "                        \"level\": batch_samples[i]['level'],\n",
    "                        \"type\": batch_samples[i]['type'],\n",
    "                        \"ground_truth\": batch_samples[i]['ground_truth'],\n",
    "                        \"predicted_solution\": predicted_text\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error during generation at batch {batch_idx+1}: {e}\")\n",
    "                # In case of error, record empty predictions for this batch\n",
    "                for i in range(current_batch_size):\n",
    "                    results_list.append({\n",
    "                        \"problem\": batch_samples[i]['problem'],\n",
    "                        \"level\": batch_samples[i]['level'],\n",
    "                        \"type\": batch_samples[i]['type'],\n",
    "                        \"ground_truth\": batch_samples[i]['ground_truth'],\n",
    "                        \"predicted_solution\": \"\"  # Empty string for predicted_text\n",
    "                    })\n",
    "                continue  # Proceed to the next batch\n",
    "    \n",
    "            # Optionally, save intermediate results every N batches\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                results_df = pd.DataFrame(results_list)\n",
    "                results_save_path = os.path.join(save_dir, f\"test_results_level_{level}_batch_{batch_idx+1}.csv\")\n",
    "                results_df.to_csv(results_save_path, index=False)\n",
    "                print(f\"Saved test results up to batch {batch_idx+1} to {results_save_path}\")\n",
    "        \n",
    "        \n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        results_save_path = os.path.join(save_dir, f\"test_results_level_{level}.csv\")\n",
    "        results_df.to_csv(results_save_path, index=False)\n",
    "        print(f\"Saved test results to {results_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dff04f",
   "metadata": {
    "_cell_guid": "ae430a9c-9cd6-4a70-af20-67d845d7d277",
    "_uuid": "7dae60b4-19ee-4bdb-95b1-5a8e4be7cb0e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd7083",
   "metadata": {
    "_cell_guid": "9a413001-f601-46cb-8086-86fecb1b309f",
    "_uuid": "d7e9be0a-73a3-45b2-b4bf-bbce73a98ad3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf957a",
   "metadata": {
    "_cell_guid": "7ffd7e86-d8d7-46c1-adc6-fb945b0d3611",
    "_uuid": "9ff9cfec-6123-455e-9a9d-2dc620551a8e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68012c1",
   "metadata": {
    "_cell_guid": "b3177369-1283-4397-80c0-cc1a43641256",
    "_uuid": "2a323ab5-5532-40ea-b6f9-c354c5f84de0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-11T18:15:15.377209",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
